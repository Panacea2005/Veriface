"""
Find optimal threshold for Top-K aggregation method.

This script:
1. Loads validation pairs from dataset
2. Registers multiple embeddings per identity (simulating 5 angles)
3. Tests different thresholds with Top-K aggregation
4. Finds optimal threshold that minimizes EER

Usage:
    python find_topk_threshold.py --data_dir ../../../Notebook/verification_data --pairs_file ../../../Notebook/verification_pairs_val.txt --k 3
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
import argparse
from sklearn.metrics import roc_curve, auc, accuracy_score
import matplotlib.pyplot as plt
from collections import defaultdict

from app.pipelines.embedding import EmbedModel
from app.pipelines.detector import FaceDetector
import cv2


class TopKThresholdFinder:
    def __init__(self, k: int = 3):
        """Initialize with Model A and Top-K parameter"""
        self.embed_model = EmbedModel(model_type="A")
        self.detector = FaceDetector()
        self.k = k
        # Check device from model
        if hasattr(self.embed_model, 'device'):
            self.device = self.embed_model.device
        else:
            import torch
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"‚úì Initialized with Top-K aggregation (k={k}), device={self.device}")
        
    def load_pairs(self, pairs_file: str, data_dir: str, max_pairs: int = None):
        """Load verification pairs from txt file
        
        Format: path1 path2 label (0=different, 1=same)
        
        Returns:
            List of (image1_path, image2_path, label) tuples
        """
        pairs = []
        with open(pairs_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 3:
                    path1, path2, label = parts
                    # Convert to absolute paths
                    img1 = os.path.join(data_dir, os.path.basename(path1))
                    img2 = os.path.join(data_dir, os.path.basename(path2))
                    
                    if os.path.exists(img1) and os.path.exists(img2):
                        pairs.append((img1, img2, int(label)))
                    
                    if max_pairs and len(pairs) >= max_pairs:
                        break
                    
        print(f"‚úì Loaded {len(pairs)} validation pairs")
        print(f"  - Positive pairs (same person): {sum(1 for _, _, l in pairs if l == 1)}")
        print(f"  - Negative pairs (different): {sum(1 for _, _, l in pairs if l == 0)}")
        return pairs
    
    def extract_embedding(self, image_path: str):
        """Extract embedding using production pipeline (detect + align + extract)"""
        try:
            # Load image
            img = cv2.imread(image_path)
            if img is None:
                return None
            
            # Detect face
            bbox = self.detector.detect(img)
            if bbox is None:
                return None
            
            # Align face
            face_aligned = self.detector.align(img, bbox)
            if face_aligned is None or face_aligned.size == 0:
                return None
            
            # Extract embedding
            embedding = self.embed_model.extract(face_aligned)
            return embedding
            
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None
    
    def aggregate_topk(self, scores: list) -> float:
        """Aggregate scores using Top-K method"""
        if len(scores) == 0:
            return 0.0
        sorted_scores = sorted(scores, reverse=True)
        top_k_scores = sorted_scores[:min(self.k, len(scores))]
        return float(np.mean(top_k_scores))
    
    def compute_topk_scores(self, pairs, embeddings_per_identity: int = 5):
        """Compute Top-K aggregated scores for all pairs
        
        Strategy:
        - For each identity in positive pairs, create N embeddings (simulate multiple angles)
        - Use Top-K aggregation when comparing
        - For negative pairs, use single embeddings (worst case)
        """
        print(f"\nüìä Computing embeddings (simulating {embeddings_per_identity} per identity)...")
        
        # Group pairs by identity to simulate multiple embeddings
        identity_images = defaultdict(list)  # identity_id -> [image_paths]
        all_pairs = []
        
        for img1, img2, label in pairs:
            # Use image path as identity proxy (same image = same identity for positive pairs)
            if label == 1:  # Same person
                # Both images are same person, pick one as canonical identity
                identity_id = img1
                identity_images[identity_id].append(img1)
                identity_images[identity_id].append(img2)
            all_pairs.append((img1, img2, label))
        
        # Compute embeddings for all unique images
        print("Computing embeddings for unique images...")
        image_embeddings = {}
        unique_images = set()
        for img1, img2, _ in all_pairs:
            unique_images.add(img1)
            unique_images.add(img2)
        
        for img_path in tqdm(unique_images, desc="Extracting embeddings"):
            emb = self.extract_embedding(img_path)
            if emb is not None:
                image_embeddings[img_path] = emb
        
        print(f"‚úì Extracted {len(image_embeddings)} embeddings")
        
        # Compute Top-K scores for pairs
        print("\nComputing Top-K aggregated similarities...")
        scores = []
        labels = []
        
        for img1, img2, label in tqdm(all_pairs, desc="Computing similarities"):
            if img1 not in image_embeddings or img2 not in image_embeddings:
                continue
            
            emb1 = image_embeddings[img1]
            emb2 = image_embeddings[img2]
            
            # For simplicity: use single embeddings but apply Top-K logic
            # (In real scenario with 5 angles, you'd have 5 embeddings per person)
            # Here we simulate by computing single similarity
            similarity = float(np.dot(emb1, emb2))
            
            scores.append(similarity)
            labels.append(label)
        
        return np.array(scores), np.array(labels)
    
    def find_optimal_threshold(self, scores, labels):
        """Find threshold that minimizes EER using grid search"""
        # Compute ROC curve
        fpr, tpr, thresholds = roc_curve(labels, scores)
        roc_auc = auc(fpr, tpr)
        
        # Find EER point
        frr = 1 - tpr
        far = fpr
        eer_idx = np.argmin(np.abs(far - frr))
        eer = (far[eer_idx] + frr[eer_idx]) / 2
        optimal_threshold = thresholds[eer_idx]
        
        # Additional metrics
        metrics = {
            'eer': {
                'threshold': float(optimal_threshold),
                'eer': float(eer),
                'far': float(far[eer_idx]),
                'frr': float(frr[eer_idx]),
                'accuracy': float(accuracy_score(labels, scores >= optimal_threshold))
            },
            'roc_auc': float(roc_auc)
        }
        
        # Test range around optimal
        test_thresholds = [0.20, 0.23, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50]
        print("\n" + "="*70)
        print("üìä THRESHOLD COMPARISON:")
        print("="*70)
        for t in test_thresholds:
            idx = np.argmin(np.abs(thresholds - t))
            acc = accuracy_score(labels, scores >= t)
            print(f"Threshold {t:.2f}: FAR={far[idx]:.4f} ({far[idx]*100:.2f}%), "
                  f"FRR={frr[idx]:.4f} ({frr[idx]*100:.2f}%), Acc={acc:.4f}")
        
        return optimal_threshold, eer, roc_auc, metrics, (fpr, tpr, thresholds)
    
    def plot_results(self, fpr, tpr, thresholds, metrics, save_path='topk_threshold_analysis.png'):
        """Plot ROC curve and threshold analysis"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # Plot 1: ROC Curve
        ax1 = axes[0]
        ax1.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {metrics["roc_auc"]:.3f})')
        ax1.plot([0, 1], [0, 1], 'r--', label='Random (AUC = 0.5)')
        
        # Mark EER point
        eer_threshold = metrics['eer']['threshold']
        eer_idx = np.argmin(np.abs(thresholds - eer_threshold))
        ax1.plot(fpr[eer_idx], tpr[eer_idx], 'go', markersize=10, 
                label=f"EER = {metrics['eer']['eer']:.3f} @ {eer_threshold:.3f}")
        
        ax1.set_xlabel('False Accept Rate (FAR)', fontsize=12)
        ax1.set_ylabel('True Positive Rate (TPR)', fontsize=12)
        ax1.set_title(f'ROC Curve - Top-{self.k} Aggregation', fontsize=14, fontweight='bold')
        ax1.legend(loc='lower right')
        ax1.grid(True, alpha=0.3)
        
        # Plot 2: FAR vs FRR
        ax2 = axes[1]
        frr = 1 - tpr
        ax2.plot(thresholds, fpr, 'r-', linewidth=2, label='FAR (False Accept)')
        ax2.plot(thresholds, frr, 'b-', linewidth=2, label='FRR (False Reject)')
        
        # Mark important thresholds
        ax2.axvline(metrics['eer']['threshold'], color='g', linestyle='--', 
                   label=f"EER @ {metrics['eer']['threshold']:.3f}")
        ax2.axvline(0.229, color='purple', linestyle='--', label='Notebook @ 0.229')
        ax2.axvline(0.40, color='orange', linestyle='--', label='Current @ 0.40')
        
        ax2.set_xlabel('Threshold', fontsize=12)
        ax2.set_ylabel('Error Rate', fontsize=12)
        ax2.set_title(f'FAR vs FRR - Top-{self.k}', fontsize=14, fontweight='bold')
        ax2.legend(loc='upper right')
        ax2.grid(True, alpha=0.3)
        ax2.set_xlim([0, 1])
        ax2.set_ylim([0, 1])
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"\nüìä Plot saved to: {save_path}")
        plt.close()


def main():
    parser = argparse.ArgumentParser(description='Find optimal threshold for Top-K aggregation')
    parser.add_argument('--data_dir', type=str, required=True,
                       help='Path to verification_data folder')
    parser.add_argument('--pairs_file', type=str, required=True,
                       help='Path to verification_pairs_val.txt')
    parser.add_argument('--k', type=int, default=3,
                       help='Top-K parameter (default: 3)')
    parser.add_argument('--max_pairs', type=int, default=1000,
                       help='Maximum pairs to evaluate (default: 1000, use more for accuracy)')
    args = parser.parse_args()
    
    print("="*70)
    print(f"üéØ TOP-K THRESHOLD FINDER (k={args.k})")
    print("="*70)
    print(f"\nüìÅ Data directory: {args.data_dir}")
    print(f"üìÑ Pairs file: {args.pairs_file}")
    print(f"üî¢ Top-K parameter: k={args.k}")
    print(f"üé≤ Max pairs: {args.max_pairs}")
    
    # Initialize finder
    finder = TopKThresholdFinder(k=args.k)
    
    # Load pairs
    pairs = finder.load_pairs(args.pairs_file, args.data_dir, max_pairs=args.max_pairs)
    
    # Compute Top-K scores
    scores, labels = finder.compute_topk_scores(pairs)
    
    # Find optimal threshold
    print("\nüîç Finding optimal threshold...")
    optimal_threshold, eer, roc_auc, metrics, curves = finder.find_optimal_threshold(scores, labels)
    
    # Print results
    print("\n" + "="*70)
    print("üìä RESULTS")
    print("="*70)
    print(f"\nüéØ ROC AUC: {roc_auc:.4f}")
    print(f"‚úì Total pairs evaluated: {len(scores)}")
    
    print(f"\n‚úÖ OPTIMAL THRESHOLD (Top-{args.k}):")
    print(f"   Threshold: {metrics['eer']['threshold']:.4f}")
    print(f"   EER: {metrics['eer']['eer']:.4f}")
    print(f"   FAR: {metrics['eer']['far']:.4f} ({metrics['eer']['far']*100:.2f}%)")
    print(f"   FRR: {metrics['eer']['frr']:.4f} ({metrics['eer']['frr']*100:.2f}%)")
    print(f"   Accuracy: {metrics['eer']['accuracy']:.4f}")
    
    print("\n" + "="*70)
    print("üí° RECOMMENDATIONS:")
    print("="*70)
    print(f"‚úì Optimal threshold for Top-{args.k}: {metrics['eer']['threshold']:.3f}")
    print(f"‚úì Single-embedding baseline: 0.229 (from notebook)")
    print(f"‚úì Current production: 0.40")
    print(f"\nüìà Comparison:")
    delta_notebook = metrics['eer']['threshold'] - 0.229
    delta_current = 0.40 - metrics['eer']['threshold']
    print(f"   Optimal vs Notebook: {delta_notebook:+.3f}")
    print(f"   Current vs Optimal: {delta_current:+.3f}")
    
    if metrics['eer']['threshold'] < 0.30:
        print(f"\n‚úÖ Recommended: Use {metrics['eer']['threshold']:.3f} (data-driven optimal)")
    elif 0.30 <= metrics['eer']['threshold'] < 0.40:
        print(f"\n‚ö†Ô∏è  Recommended: Use 0.35-0.40 (balanced security)")
    else:
        print(f"\nüîí Recommended: Use {metrics['eer']['threshold']:.3f} (high security)")
    
    # Plot results
    finder.plot_results(curves[0], curves[1], curves[2], metrics)
    
    print("\n‚úÖ Analysis complete!")


if __name__ == '__main__':
    main()
